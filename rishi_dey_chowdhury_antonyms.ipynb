{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "966c8e46",
   "metadata": {},
   "source": [
    "# Task-1.2: Sentence with Antonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7422865",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f43c53",
   "metadata": {},
   "source": [
    "NLTK library is used for the purpose of tokenization and Wordnet for antonym generation. The Hugging Face's datasets library provides us with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a855dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import string\n",
    "from datasets import load_dataset\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30dbde2",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e541c",
   "metadata": {},
   "source": [
    "The Multi-Genre Natural Language Inference (MultiNLI) corpus is a crowd-sourced collection of 433k sentence pairs annotated with textual entailment information. We load this library available through the datasets library below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28092dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/rishideychowdhury/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011440753936767578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f91c6c3c38c409993f5c8f29b825df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('glue', 'mnli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9709faf9",
   "metadata": {},
   "source": [
    "The first $5000$ sentences are chosen for the purpose of this negation task and will be used further in the second task for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1818e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset['train']['premise'][:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b1dcd",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab3abd",
   "metadata": {},
   "source": [
    "For any NLP workflow, tokenization is the most basic step towards handling text data and below the word_tokenizer is used for this task provided by the NLTK library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d3cb648",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tokenized = [word_tokenize(sent) for sent in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d624482",
   "metadata": {},
   "source": [
    "Since, our purpose is the generate a sentence with all adjectives being replaced with their antonyms, if available. We will start by tagging the parts of speech of the tokens for each sentence using the NLTK's `pos_tagger`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe63e79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos_tagged = [pos_tag(tokenized_sent) for tokenized_sent in data_tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3531b04a",
   "metadata": {},
   "source": [
    "The following helper function helps us find the antonymns for a word using the WordNet from NLTK's library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c78e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_antonyms(word):\n",
    "    antonyms = [] # To store the antonyms of the input word\n",
    "    for syn in wn.synsets(word): # Looking for the synonym set in WordNet\n",
    "        for i in syn.lemmas(): # Looking for the lemmas associated with each lemma in the synonym set\n",
    "             if i.antonyms(): # Finding the antonyms based on this lemma\n",
    "                antonyms.append(i.antonyms()[0].name()) \n",
    "    antos = sorted(set(antonyms)) # Sorts the antonyms retrieved in lexicographical order\n",
    "    return list(antos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba868bec",
   "metadata": {},
   "source": [
    "The original sentences are traversed token-wise and then adjectives are replaced with the lexicographically smallest antonym retrieved from WordNet and the new sentence is generated keeping in mind the proper spacing as in the original sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae5a8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores the sentences with antonyms of adjectives replaced in place of orginial adjectives\n",
    "data_antonymed = list()\n",
    "for tokens in data_pos_tagged:\n",
    "    anto_sent_tokens = list() # stores the fake sentence tokens for the selected sentence\n",
    "    \n",
    "    for token in tokens:\n",
    "        if 'J' in token[1]: # Identifying the adjectives from the POS tags\n",
    "            ants = find_antonyms(token[0]) # Finding the antonyms corresponding to this adjective using above func\n",
    "            if ants: # If antonym exists then add the first antonym as it is lexicographically the smallest\n",
    "                if token[0].endswith('ing'): \n",
    "                    # Handling common situation of token ending with 'ing'\n",
    "                    anto_sent_tokens.append(ants[0] if ants[0].endswith('ing') else ants[0][:-1] + 'ing')\n",
    "                elif token[0].endswith('ed'):\n",
    "                    # Handling common situation of token ending with 'ed'\n",
    "                    anto_sent_tokens.append(ants[0] if ants[0].endswith('ed') else ants[0][:-1] + 'ed')\n",
    "                else:\n",
    "                    anto_sent_tokens.append(ants[0])\n",
    "            else: # If no antonym exists then simply add the original word\n",
    "                anto_sent_tokens.append(token[0])\n",
    "        else: # If not adjective then simply add it as it is\n",
    "            anto_sent_tokens.append(token[0])\n",
    "            \n",
    "    # Since, 's, etc are tokenized simply adding them separated by space changes the sentence, we deal with that below\n",
    "    # Even the punctuation marks are separated out by space if we simply use join. Hence, we process the spaces aptly.\n",
    "    antonym_sentence = anto_sent_tokens[0]\n",
    "    for token in anto_sent_tokens[1:]:\n",
    "        antonym_sentence += token if token[0] in string.punctuation or token == \"n't\" else \" \" + token\n",
    "    data_antonymed.append(antonym_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10ced7",
   "metadata": {},
   "source": [
    "The following are the original sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82dcaebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conceptually cream skimming has two basic dime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know during the season and i guess at at y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One of our number will carry out your instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do you know? All this is their information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeah i tell you what though if you go price so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>right because clothes are some are really expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>I'll admit that it wasn't he who bought strych...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Particularly noteworthy are the ornately Frenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Do you mean tall or short?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Some writers hint that the only reason Ta Mok ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     Conceptually cream skimming has two basic dime...\n",
       "1     you know during the season and i guess at at y...\n",
       "2     One of our number will carry out your instruct...\n",
       "3     How do you know? All this is their information...\n",
       "4     yeah i tell you what though if you go price so...\n",
       "...                                                 ...\n",
       "4995  right because clothes are some are really expe...\n",
       "4996  I'll admit that it wasn't he who bought strych...\n",
       "4997  Particularly noteworthy are the ornately Frenc...\n",
       "4998                         Do you mean tall or short?\n",
       "4999  Some writers hint that the only reason Ta Mok ...\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a737ad35",
   "metadata": {},
   "source": [
    "The following are the sentences in which the adjective is replaced by it's lexicographically smallest antonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76898af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conceptually cream skimming has two incidental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know during the season and i guess at at y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One of our number will carry out your instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do you know? All this is their information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeah i tell you what though if you go price so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>right because clothes are some are really chea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>I'll admit that it wasn't he who bought strych...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Particularly noteworthy are the ornately Frenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Do you mean short or long?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Some writers hint that the only reason Ta Mok ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     Conceptually cream skimming has two incidental...\n",
       "1     you know during the season and i guess at at y...\n",
       "2     One of our number will carry out your instruct...\n",
       "3     How do you know? All this is their information...\n",
       "4     yeah i tell you what though if you go price so...\n",
       "...                                                 ...\n",
       "4995  right because clothes are some are really chea...\n",
       "4996  I'll admit that it wasn't he who bought strych...\n",
       "4997  Particularly noteworthy are the ornately Frenc...\n",
       "4998                         Do you mean short or long?\n",
       "4999  Some writers hint that the only reason Ta Mok ...\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_antonymed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173935cc",
   "metadata": {},
   "source": [
    "Writing the results in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eb328a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"rishi_dey_chowdhury_antonyms.csv\"\n",
    "fields = ['index', 'real_sentence', 'fake_sentence'] \n",
    "with open(filename, 'w') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile) \n",
    "    csvwriter.writerow(fields)\n",
    "    for i in range(len(data)):\n",
    "        csvwriter.writerow([i, data[i], data_antonymed[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
